# Quick_and_easy_LLM
From LLM basics to the Jerevan radio

LaMini is a lightweight large language model of the encoder-decoder architecture. 
It employs a mere 768 features and 11 transformer blocks, so it can also run on a CPU. 
Here, we present simple Python codes that provide machines based on such LLM: 
chatbot, autoencoder, generator, classifier, and finally, the radio Jerevan 
(a fictional radio from the era of the Soviet Union that modifies facts so much 
that reported news is totally different). 

We have created these codes for educational purposes. One can directly use the 
transformer pipelines and implement most of these tasks in a few lines of code. 
However, our solution lets you observe how they internally work, i.e., what is inside. 
Our codes are simplified to be easily readable. As a result, they are also slower and 
provide lower-quality results. 
